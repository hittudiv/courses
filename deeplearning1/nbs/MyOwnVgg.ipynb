{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu0 is not available  (error: Unable to get the number of gpus available: CUDA driver version is insufficient for CUDA runtime version)\n"
     ]
    }
   ],
   "source": [
    "%pwd\n",
    "from theano.sandbox import cuda\n",
    "cuda.use('gpu0')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "base= os.getcwd() + \"/data/redux\"\n",
    "base= os.getcwd() + \"/data/redux/sample\"\n",
    "train= base+\"/train\"\n",
    "test= base+\"/test\"\n",
    "valid= base+\"/valid\"\n",
    "results_path = base+\"/results\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import bcolz\n",
    "def plot(img):\n",
    "    plt.imshow(img)\n",
    "def save_array(fname, arr):\n",
    "    c=bcolz.carray(arr, rootdir=fname, mode='w')\n",
    "    c.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "import json   \n",
    "import keras.preprocessing.image as preprocess\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from keras.layers.core import Lambda, Flatten, Dropout, Dense\n",
    "from keras.layers.convolutional import ZeroPadding2D, Convolution2D, MaxPooling2D\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "vgg_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape((3,1,1))\n",
    "def vgg_preprocess(x):\n",
    "    \"\"\"\n",
    "        Subtracts the mean RGB value, and transposes RGB to BGR.\n",
    "        The mean RGB was computed on the image set used to train the VGG model.\n",
    "\n",
    "        Args: \n",
    "            x: Image array (height x width x channels)\n",
    "        Returns:\n",
    "            Image array (height x width x transposed_channels)\n",
    "    \"\"\"\n",
    "    x = x - vgg_mean\n",
    "#     print x\n",
    "#     import pdb;pdb.set_trace()\n",
    "    return x[:, ::-1] # reverse axis rgb->bgr\n",
    "\n",
    "class hgg:\n",
    "    def get_classes(self):\n",
    "        fname = 'imagenet_class_index.json'\n",
    "        fpath = get_file(fname, self.FILE_PATH+fname, cache_subdir='models')\n",
    "        with open(fpath) as f:\n",
    "            class_dict = json.load(f)\n",
    "        self.classes = [class_dict[str(i)][1] for i in range(len(class_dict))]\n",
    "\n",
    "    def get_batches(self,path, shuffle=True, batch_size=8, rotation_range=10 ,width_shift_range=10, height_shift_range=10, shear_range=0.3, class_mode='categorical' ):\n",
    "#         imageGenerator doc at https://keras.io/preprocessing/image/\n",
    "        imageGenerator = preprocess.ImageDataGenerator(\n",
    "#             rotation_range=rotation_range,\n",
    "#             width_shift_range=width_shift_range,\n",
    "#             height_shift_range=height_shift_range,\n",
    "#             shear_range=shear_range,\n",
    "#             zoom_range=0\n",
    "        )\n",
    "        return imageGenerator.flow_from_directory(\n",
    "            shuffle=shuffle,\n",
    "            directory=path, \n",
    "            target_size=(224,224),\n",
    "            batch_size=batch_size,\n",
    "            class_mode=class_mode\n",
    "        )\n",
    "    def __init__(self):\n",
    "        self.FILE_PATH = 'http://files.fast.ai/models/'\n",
    "\n",
    "        self.createModel()\n",
    "        self.get_classes()\n",
    "        pass\n",
    "    def createModel(self,):\n",
    "        # Sequential doc at https://keras.io/getting-started/sequential-model-guide/\n",
    "        self.model=Sequential()\n",
    "        self.model.add(Lambda(vgg_preprocess, input_shape=(3,224,224), output_shape=(3,224,224)))\n",
    "        self.addConvLayer(2,64)\n",
    "        self.addConvLayer(2,128)\n",
    "        self.addConvLayer(3,256)\n",
    "        self.addConvLayer(3,512)\n",
    "        self.addConvLayer(3,512)\n",
    "        \n",
    "        self.model.add(Flatten())\n",
    "        \n",
    "        self.model.add(Dense(4096,activation='relu'))\n",
    "        self.model.add(Dropout(0.5))\n",
    "        \n",
    "        self.model.add(Dense(4096,activation='relu'))\n",
    "        self.model.add(Dropout(0.5))\n",
    "        \n",
    "        \n",
    "        self.model.add(Dense(1000,activation='softmax'))\n",
    "        \n",
    "        \n",
    "        fname=\"vgg16.h5\"\n",
    "        self.model.load_weights(get_file(fname, self.FILE_PATH+fname, cache_subdir='models'))\n",
    "        \n",
    "    def addConvLayer(self,layers,filters):\n",
    "        # Convolution2D https://keras.io/layers/convolutional/\n",
    "        for i in range(layers):\n",
    "            self.model.add(ZeroPadding2D((1,1)))\n",
    "            self.model.add(Convolution2D(filters,3,3,activation='relu'))\n",
    "        self.model.add(MaxPooling2D((2,2),strides=(2,2)))\n",
    "        \n",
    "    def ModifyLastLayerToNewOutput(self, no_of_outputs):\n",
    "        self.model.pop()\n",
    "        for layer in self.model.layers: layer.trainable=False\n",
    "        self.model.add(Dense(no_of_outputs,activation='softmax'))\n",
    "        print no_of_outputs\n",
    "        self.compile()\n",
    "    def finetune(self,batches):\n",
    "        self.ModifyLastLayerToNewOutput(batches.nb_class)\n",
    "        classes = list(iter(batches.class_indices)) # get a list of all the class labels\n",
    "        \n",
    "        # batches.class_indices is a dict with the class name as key and an index as value\n",
    "        # eg. {'cats': 0, 'dogs': 1}\n",
    "\n",
    "        # sort the class labels by index according to batches.class_indices and update model.classes\n",
    "        for c in batches.class_indices:\n",
    "            classes[batches.class_indices[c]] = c\n",
    "        self.classes = classes\n",
    "        \n",
    "        \n",
    "    def compile(self, lr=0.001):\n",
    "        self.model.compile(optimizer=Adam(lr=lr), loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    def fit(self,train_batches, validation_batches):\n",
    "        self.model.fit_generator(train_batches, \n",
    "                        samples_per_epoch = train_batches.nb_sample,\n",
    "                        nb_epoch=1, \n",
    "                        validation_data = validation_batches,\n",
    "                        nb_val_samples = validation_batches.nb_sample,\n",
    "                       )\n",
    "   \n",
    "h = hgg()\n",
    "# from vgg16 import Vgg16\n",
    "\n",
    "# h=Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 2] No such file or directory: '/opt/courses/deeplearning1/nbs/data/redux/sample/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mOSError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-384fe3b3da98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mvalidation_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# validation_batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-2ce1b4a9e021>\u001b[0m in \u001b[0;36mget_batches\u001b[0;34m(self, path, shuffle, batch_size, rotation_range, width_shift_range, height_shift_range, shear_range, class_mode)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mclass_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         )\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/preprocessing/image.pyc\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links)\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[0msave_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m             follow_links=follow_links)\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/preprocessing/image.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, dim_ordering, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 2] No such file or directory: '/opt/courses/deeplearning1/nbs/data/redux/sample/train'"
     ]
    }
   ],
   "source": [
    "batch_size=8\n",
    "train_batches = h.get_batches(train, batch_size=batch_size)\n",
    "validation_batches = h.get_batches(valid, batch_size=batch_size)\n",
    "test_batches = h.get_batches(test, batch_size=batch_size)\n",
    "# validation_batches\n",
    "# plot(validation_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.finetune(train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_now=False\n",
    "\n",
    "no_of_epochs=3\n",
    "if train_now==True:\n",
    "    latest_weights_filename = None\n",
    "    for epoch in range(no_of_epochs):\n",
    "        print \"Running epoch: %d\" % epoch\n",
    "        if(epoch>=2):\n",
    "            h.model.optimizer.lr = 0.001\n",
    "        h.fit(train_batches, validation_batches)\n",
    "        latest_weights_filename = '/ft%d.h5' % epoch\n",
    "        h.model.save_weights(results_path+latest_weights_filename)\n",
    "    print \"Completed %s fit operations\" % no_of_epochs\n",
    "else:\n",
    "    print \"loading from saved_model\"\n",
    "    h.model.load_weights(results_path+\"/vgg/ft2.h5\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_batches = h.get_batches(valid, batch_size=batch_size, shuffle=False, class_mode=None)\n",
    "validation_batches = h.get_batches(valid, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "preds=h.model.predict_generator(validation_batches, validation_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_dog = np.round(1- preds)\n",
    "print is_dog[:5]\n",
    "filenames = validation_batches.filenames\n",
    "print filenames[:5]\n",
    "print len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"submit.txt\",\"a\") as f:\n",
    "    f.write(\"id,label\\n\")\n",
    "    for i in range(len(preds)):\n",
    "        if(is_dog[i][0]==1):\n",
    "            is_dog[i][0]=0.05\n",
    "        else:\n",
    "            is_dog[i][0]=0.95\n",
    "        print filenames[i][8:-4],\",\",is_dog[i][0]\n",
    "        f.write(\"%s,%s\\n\"%(str(filenames[i][8:-4]),str(is_dog[i][0])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import random\n",
    "isdog = preds[:,1]\n",
    "isdog = isdog.clip(min=0.05, max=0.95)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=int(random.random()*len(preds))\n",
    "print idx\n",
    "print preds[idx]\n",
    "print isdog[idx]\n",
    "print filenames[idx]\n",
    "print len(preds)\n",
    "\n",
    "Image.open(valid+\"/\" + filenames[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'validation_batches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b2a260576ae6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mn_view\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mexpected_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;31m#0 or 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m#Round our predictions to 0/1 to generate labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'validation_batches' is not defined"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from numpy.random import random, permutation\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    (This function is copied from the scikit docs.)\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print(cm)\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "from keras.preprocessing import image\n",
    "\n",
    "#Helper function to plot images by index in the validation set \n",
    "#Plots is a helper function in utils.py\n",
    "def plots_idx(idx, titles=None):\n",
    "    plots([image.load_img(valid + \"/\" +filenames[i]) for i in idx], titles=titles)\n",
    "def plots(ims, figsize=(12,6), rows=1, interp=False, titles=None):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0,2,3,1))\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, len(ims)//rows, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')\n",
    "\n",
    "\n",
    "#Number of images to view for each visualization task\n",
    "n_view = 4\n",
    "from sklearn.metrics import confusion_matrix\n",
    "expected_labels = validation_batches.classes #0 or 1\n",
    "\n",
    "#Round our predictions to 0/1 to generate labels\n",
    "our_predictions = preds[:,0]\n",
    "our_labels = np.round(1-our_predictions)\n",
    "\n",
    "cm = confusion_matrix(expected_labels, our_labels)\n",
    "plot_confusion_matrix(cm, validation_batches.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-05022dbc3502>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/test_preds.dat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msave_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/filenames.dat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preds' is not defined"
     ]
    }
   ],
   "source": [
    "save_array(results_path + '/test_preds.dat', preds)\n",
    "save_array(results_path + '/filenames.dat', filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'our_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9661d7bbb9e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#1. A few correct labels at random\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mour_labels\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mexpected_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Found %d correct labels\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_view\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'our_labels' is not defined"
     ]
    }
   ],
   "source": [
    "#1. A few correct labels at random\n",
    "correct = np.where(our_labels!=expected_labels)[0]\n",
    "print \"Found %d correct labels\" % len(correct)\n",
    "idx = permutation(correct)[:n_view]\n",
    "print idx\n",
    "plots_idx(idx, our_predictions[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
